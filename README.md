# ğŸ“Š Gig Worker Earnings Forecasting API (Flask + IBM Watsonx + Android)

## ğŸš€ Overview

This project is a **Flask-based backend** for the *GigWorkers Fair Pay Monitor* â€” a system designed to help gig-platform drivers and couriers detect unexpected dips in income and take corrective action. It uses **IBM Granite Time Series - ibm/granite-ttm-512-96-r2** to forecast income and identify anomalies, allowing workers to understand fluctuations in earnings and get actionable insights.

This backend is intended to be used in conjunction with a **mobile Android application**, which visualizes forecasts, alerts, and explanations generated by this service.

---

## ğŸ§  Problem Statement

> Studies in 2024 show that gig workers are working more hours but earning 3â€“14% less. Income drops vary by city and platform.

Gig workers currently lack real-time tools to:

- Monitor earnings trends.
- Forecast income dips.
- Receive timely alerts for negotiation or platform-switching.
- Get transparent, understandable explanations for earnings fluctuations.

---

## ğŸ”§ Features

- Upload weekly payout CSVs (platform, earnings, hours).
- Use ibm/granite-ttm-512-96-r2 model for **multivariate time series forecasting**.
- Automatically detect anomalies (actual < P10 or > P90).
- Trigger alert notifications and generate wage-claim report PDFs.
- Provide **plain-language LLM chat explanations** for pay drops.
- Send forecast and alert data to mobile app for visualization.

---

## ğŸ” Data Flow

1. **Gig worker** uploads earnings CSV from platforms like Uber, Zomato.
2. File parsed and cleaned â†’ sent to backend.
3. Flask backend forecasts payouts using Granite TST API.
4. Alerts generated if earnings fall outside expected range.
5. Explanation generated via LLM.
6. Android app fetches results for visualization.

---

## ğŸ—ƒï¸ Data Design

| Stream | Granularity | Key Fields |
|--------|-------------|------------|
| `payouts_raw` | weekly/worker | worker_id, platform, week_start, gross_pay, tips, hours_worked |
| `calendar_exog` | daily | holiday_flag, petrol_price_idx, CPI, weather_idx |
| `alerts` | event-based | worker_id, week_start, anomaly_score, message |

---

## ğŸ’¬ Example Use Case

Imagine a gig worker in Mumbai working with Zomato. They enter their weekly gross earnings for the past four weeks into the app. The backend system performs the following:

  - Analyzes weekly earnings trends to assess whether the income received aligns with forecasted gross pay based on historical earning patterns.

  - Compares their earnings with those of other gig workers on various platforms in Mumbai to determine if they are earning in line with market trends.

  - Predicts their potential earnings for the next seven weeks using historical data.

  - Sends this data to the Android app, which displays the insights in a line chart along with personalized tips to help improve earnings.

---

## ğŸ“‚ Project Structure

```
gig-forecast-api/
â”œâ”€â”€ gig_worker.py                         # Flask application
â”œâ”€â”€ combined_gig_worker_data.json # Local cache of historical and user data
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Documentation
```

---

## ğŸ“± Android App Integration

The Android frontend will:

1. Collect input from users (platform, city, historical weekly gross_pay).
2. Send a POST request to the backend endpoint.
3. Receive prediction/comparison response in JSON.
4. Visualize the results using line charts, bar graphs, etc.

> âš ï¸ Dates must be in `YYYY-MM-DD` format (e.g., `"2025-01-01"`).

---

## ğŸš€ API Endpoints

### 1. `/user_data_comparision_for_provided_week` [POST]

**Purpose**: Compare user data with historical data, excluding userâ€™s data and predict if he could have earned more considering the patterns from Historic Data based on differnet Parameters like Weather, Petrol Price, CPI , Holidays.

**Request JSON Example**:
```json
[
  {
    "worker_id": "W0001",
    "platform": "Zomato",
    "city": "Mumbai",
    "week_start": "2025-01-01",
    "gross_pay": 4500
  },
  {
    "worker_id": "W0001",
    "platform": "Zomato",
    "city": "Mumbai",
    "week_start": "2025-01-08",
    "gross_pay": 4600
  }
]
```

**Response JSON Example**:
```json
[
  {
    "week_start": "2025-02-01",
    "gross_pay": 4700,
    "platform": "Zomato",
    "city": "Mumbai"
  },
  {
    "week_start": "2025-02-08",
    "gross_pay": 4850,
    "platform": "Zomato",
    "city": "Mumbai"
  }
]
```

---

### 2. `/user_data_next_week_forcast` [POST]

**Purpose**: Predict next requested weeks of earnings using user + historical data.

**Request JSON**: Same format as above.

**Response JSON**: Predicted values for upcoming requested weeks.

---

## ğŸ§ª Run the Flask Backend Locally

### 1. ğŸ”§ Clone the Repo

```bash
git clone https://github.com/your-org/gig-forecast-api.git
cd gig-forecast-api
```

### 2. ğŸ“¦ Create Virtual Environment & Install Requirements

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. ğŸ› ï¸ Setup IBM Watsonx & COS Credentials

Edit the `app.py` and update these values:

```python
IAM_API_KEY = "<your-watsonx-api-key>"
project_id = "<your-watsonx-project-id>"
```

Cloud Object Storage config:
```python
cos_client = ibm_boto3.client(
    service_name='s3',
    ibm_api_key_id='<your-cos-api-key>',
    ibm_auth_endpoint="https://iam.cloud.ibm.com/identity/token",
    endpoint_url='<your-cos-endpoint>'
)
```

---


### 4. ğŸš€ Start the Flask Server

```bash
flask run
```

Backend will be available at:  
**`http://localhost:8532/`**

---

